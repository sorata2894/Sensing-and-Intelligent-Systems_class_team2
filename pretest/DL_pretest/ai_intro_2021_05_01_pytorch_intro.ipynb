{"cells":[{"cell_type":"markdown","metadata":{"id":"lIUGR61n6291"},"source":["Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then run the cells accordingly.\n","\n","Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"77NOrffR6293","executionInfo":{"status":"ok","timestamp":1645019087983,"user_tz":-480,"elapsed":1,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"}}},"outputs":[],"source":["NAME = \"曾致崴\"\n","COLLABORATORS = \"王靖淳\""]},{"cell_type":"markdown","metadata":{"id":"tz446rf06294"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"X216V7dvF1Ot"},"source":["# Introducing PyTorch\n","\n","Parts of the materials are from the [Brains, Minds and Machines summer course 2018](http://cbmm.mit.edu/summer-school/2018).\n","\n","Some materials are adpated from Dive into Deep Learning\n","https://d2l.ai/ \n"]},{"cell_type":"markdown","metadata":{"id":"7Ki-xnL6bHSd"},"source":["PyTorch is an open source library for numerical computation using  computation graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. \n","\n","Similar to python programming, we can add and execute a node to the computation graph immediately. This property makes it easy to debug the code and inspect the values in the network."]},{"cell_type":"markdown","metadata":{"id":"6Gms-JZSF1Ov"},"source":["PyTorch provides several useful modules.\n","\n","*  [ ```torch.nn```](https://pytorch.org/docs/stable/nn.html): This module provides the building blocks to create the networks, including the implementation of the various layers. \n","*  [```torch.optim```](https://pytorch.org/docs/stable/optim.html): This module provides various optimization algorithms. Most commonly used methods are already supported.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"aFNx9ZejF1Ov","executionInfo":{"status":"ok","timestamp":1645019095353,"user_tz":-480,"elapsed":5757,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"}}},"outputs":[],"source":["import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{"id":"uJ7X1y9SoPTH"},"source":["## Tensors\n","\n","Tensors are the leaf variables in the computation graph. By default, a tensor is initialized randomly. \n","\n","You can perform the operations defined in [```torch.Tensor```](https://pytorch.org/docs/stable/tensors.html) on the tensors."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1047,"status":"ok","timestamp":1645019096398,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"ith3SmB_qRas","outputId":"311affbd-60c1-461a-ef4e-7e3e169abf14"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-6.8878e-12,  3.0848e-41,  3.7835e-44],\n","        [ 0.0000e+00,         nan,  3.0848e-41],\n","        [ 1.3733e-14,  6.4069e+02,  4.3066e+21],\n","        [ 1.1824e+22,  4.3066e+21,  6.3828e+28],\n","        [ 3.8016e-39,  3.0848e-41, -1.4202e-12]])\n","tensor([[0.2150, 0.0450, 0.9069],\n","        [0.5880, 0.3780, 0.9628],\n","        [0.9493, 0.3219, 0.1990],\n","        [0.5501, 0.5545, 0.5037],\n","        [0.4084, 0.4961, 0.1181]])\n","tensor([[ 0.7136,  0.9217, -0.9703],\n","        [ 0.9994, -0.7058,  0.2503],\n","        [-0.8003, -0.1351, -0.2828],\n","        [-0.4698,  0.9856,  0.8299],\n","        [-0.4351,  0.6965,  0.2197]])\n","tensor([[2.1499e-01, 4.5021e-02, 9.0694e-01],\n","        [5.8801e-01,        nan, 9.6284e-01],\n","        [9.4933e-01, 6.4101e+02, 4.3066e+21],\n","        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n","        [4.0835e-01, 4.9613e-01, 1.1808e-01]])\n","tensor([[2.1499e-01, 4.5021e-02, 9.0694e-01],\n","        [5.8801e-01,        nan, 9.6284e-01],\n","        [9.4933e-01, 6.4101e+02, 4.3066e+21],\n","        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n","        [4.0835e-01, 4.9613e-01, 1.1808e-01]])\n","torch.Size([5, 3])\n"]}],"source":["A = torch.Tensor(5, 3)\n","B = torch.rand(5, 3)\n","C = torch.Tensor(5, 3).uniform_(-1, 1)\n","\n","print(A)\n","print(B)\n","print(C)\n","print(A + B)\n","print(torch.add(A, B))\n","print(C.size())"]},{"cell_type":"markdown","metadata":{"id":"J_GZcYj_F1O7"},"source":["### Tensor Types\n","source: http://pytorch.org/docs/master/tensors.html"]},{"cell_type":"markdown","metadata":{"id":"xPf-5DkeF1O7"},"source":["|Data type |CPU Tensor| \n","|----------|------|\n","|32-bit floating point\t\t|torch.FloatTensor\t|\n","|64-bit floating point\t\t|torch.DoubleTensor\t|\n","|16-bit floating point\t\t|torch.HalfTensor\t|\n","|8-bit integer (unsigned)\t|torch.ByteTensor\t| \n","|8-bit integer (signed)\t\t|torch.CharTensor\t|\n","|16-bit integer (signed)\t|torch.ShortTensor\t|\n","|32-bit integer (signed)\t|torch.IntTensor\t|\n","|64-bit integer (signed)\t|torch.LongTensor\t|"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1645019096398,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"mDLjCxWlF1O-","outputId":"9b4cd42f-d393-4be4-d072-b2a55a5d9ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.DoubleTensor\n","torch.FloatTensor\n"]}],"source":["# Data type inferred from numpy\n","print(torch.from_numpy(np.random.rand(5, 3)).type())\n","print(torch.from_numpy(np.random.rand(5, 3).astype(np.float32)).type())"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"8W-4La3DF1PJ"},"source":["### Reshape"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1645019096399,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"pj9yzqZ7F1PK","outputId":"ca053442-7d36-4375-9259-4c1e3e90655f"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 10, 15])\n","torch.Size([50, 15])\n","torch.Size([50, 1, 15])\n","torch.Size([50, 15])\n","\n","torch.Size([10, 5, 15])\n","torch.Size([5, 15, 10])\n","torch.Size([10, 15, 5])\n","torch.Size([10, 15, 5])\n"]}],"source":["y = torch.randn(5, 10, 15)\n","print(y.size())\n","print(y.view(-1, 15).size())  # Same as doing y.view(50, 15)\n","print(y.view(-1, 15).unsqueeze(1).size()) # Adds a dimension at index 1.\n","print(y.view(-1, 15).unsqueeze(1).squeeze().size())\n","# If input is of shape: (Ax1xBxCx1xD)(Ax1xBxCx1xD) then the out Tensor will be of shape: (AxBxCxD)(AxBxCxD)\n","print()\n","print(y.transpose(0, 1).size())\n","print(y.transpose(1, 2).size())\n","print(y.transpose(0, 1).transpose(1, 2).size())\n","print(y.permute(1, 2, 0).size())"]},{"cell_type":"markdown","metadata":{"id":"U4zIKgFDF1PM"},"source":["### Repeat"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1645019096644,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"GJddLYPHF1PM","outputId":"4de270ac-71a2-4236-da80-417a9151d638"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 100, 15])\n","torch.Size([50, 100, 15])\n"]}],"source":["print(y.view(-1, 15).unsqueeze(1).expand(50, 100, 15).size())\n","print(y.view(-1, 15).unsqueeze(1).expand_as(torch.randn(50, 100, 15)).size())"]},{"cell_type":"markdown","metadata":{"id":"4jdEr1zUpRYH"},"source":["## Numpy Bridge\n","\n","You can convert a tensor to a numpy array easily and vice versa. The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the value of the other."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1645019100045,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"UbTzqrGFpQN6","outputId":"3685fc5c-3117-4c2b-a9e9-e28695771585"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 1. 1. 1. 1.]\n","tensor([1., 2., 1., 1., 1.])\n","tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"]}],"source":["# convert pytorch tensor to numpy\n","a = torch.ones(5)\n","print(a.numpy())\n","a.numpy()[1] = 2\n","print(a)\n","\n","# convert numpy to pytorch tensor\n","b = np.ones(5)\n","print(torch.from_numpy(b))"]},{"cell_type":"markdown","metadata":{"id":"co3zw3FO_kC3"},"source":["## Computing Gradient with Autograd\n","\n","PyTorch uses a technique called automatic differentiation. That is, we have a recorder that records what operations we have performed, and then it replays it backward to compute our gradients. This technique is especially powerful when building neural networks, as we save time on one epoch by calculating differentiation of the parameters at the forward pass itself.\n","\n","Once you finish your computation in the forward pass, you can call ```.backward()``` and have all the gradients computed automatically. You can access the gradient w.r.t. this tensor in ```.grad```.\n"]},{"cell_type":"markdown","metadata":{"id":"JObasUx0_z1D"},"source":["Create a tensor and set ``requires_grad=True`` to track computation with it"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645019100563,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"caVVOgTd-FbI","outputId":"7ab33e42-afd6-4dd9-d3aa-d184128085f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"]}],"source":["x = torch.ones(2, 2, requires_grad=True)\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"aJCQOqHZ-IKW"},"source":["Do a tensor operation:\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1645019101545,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"XbTBCrBwpIIo","outputId":"66bae890-45a3-4c9c-f7a5-ec9cfdcdcc3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)\n"]}],"source":["y = x + 2\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"_VmRabUE-T9d"},"source":["``y`` was created as a result of an operation, so it has a ``grad_fn``."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1645019102555,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"7tBbuCKw-U0Y","outputId":"b7f76ab6-a5c3-449c-8578-89649e518b83"},"outputs":[{"output_type":"stream","name":"stdout","text":["<AddBackward0 object at 0x7fe9aa940850>\n"]}],"source":["print(y.grad_fn)"]},{"cell_type":"markdown","metadata":{"id":"eXyxWLO6_Awy"},"source":["Do more operations on ``y``\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1645019102926,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"p_KK_foP_BTc","outputId":"c15eb83c-c1ed-43d4-8177-774638a11ff9"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[27., 27.],\n","        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"]}],"source":["z = y * y * 3\n","out = z.mean()\n","\n","print(z, out)"]},{"cell_type":"markdown","metadata":{"id":"x8wR6cmd-zCY"},"source":["Gradients\n","---------\n","Let's backprop now.\n","Because ``out`` contains a single scalar, ``out.backward()`` is\n","equivalent to ``out.backward(torch.tensor(1.))``."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1645019104432,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"9FfRzHyI-Ykr","outputId":"a226faf6-d89a-40db-b71d-4c4bff64da0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])\n"]}],"source":["# compute gradients\n","out.backward()\n","# print gradients d(out)/dx\n","print(x.grad.data)"]},{"cell_type":"markdown","metadata":{"id":"SdwzeGNu_Yrb"},"source":["You should have got a matrix of ``4.5``. Let’s call the ``out``\n","*Tensor* “$o$”.\n","We have that $o = \\frac{1}{4}\\sum_i z_i$,\n","$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n","Therefore,\n","$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n","$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$."]},{"cell_type":"markdown","metadata":{"id":"9lu-rghKF1PP"},"source":["## Using GPU\n","\n","To train on the GPU, we need to move all tensors and layers to the GPU first. You can do this by calling ```.cuda()``` or create a tensor with a device location. If you have multiple GPUs, you can select which GPU you want to use by setting ```cuda:n``` where n is the device id of the GPU. "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10054,"status":"ok","timestamp":1645019115938,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"hbMCmh0KF1PP","outputId":"e2432da3-2c4c-4008-a0f3-bc48aa1224f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2., 2.],\n","        [2., 2.]], device='cuda:0', grad_fn=<AddBackward0>)\n","tensor([[2., 2.],\n","        [2., 2.]], dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n"]}],"source":["# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"]},{"cell_type":"markdown","metadata":{"id":"-Mq6HpKjF1PR"},"source":["### Part A: Move tensors on the CPU -> GPU (1 point)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"deletable":false,"executionInfo":{"elapsed":577,"status":"error","timestamp":1644995396253,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"4fjoAgN5F1PS","nbgrader":{"cell_type":"code","checksum":"c17fdbbd7a8067cd9198b089d3a17b37","grade":false,"grade_id":"cell-4f9c43d4b7fc3dda","locked":false,"schema_version":3,"solution":true,"task":false},"outputId":"92fa531d-4da1-4d4f-fd3b-1606e52e4bdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.1610,  0.3224,  0.4260],\n","        [ 0.3430,  0.8005, -0.1152],\n","        [ 0.1741,  0.7376, -0.4905],\n","        [ 0.3780, -0.5211, -0.8933],\n","        [-0.9146, -0.6578, -0.9438]])\n"]},{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-41e1e024cd09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m: "]}],"source":["x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n","print(x)\n","\n","# YOUR CODE HERE\n","device = torch.device(\"cuda\")\n","a = torch.ones_like(x, device=device)\n","x = x.to(device)\n","# print(x)\n","\n","raise NotImplementedError()"]},{"cell_type":"code","execution_count":20,"metadata":{"deletable":false,"editable":false,"id":"JgQ5I9oWtSwT","nbgrader":{"cell_type":"code","checksum":"6f97af0b835dfdc7d0048247fdb3f2db","grade":true,"grade_id":"cell-218818aecb12dd38","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"executionInfo":{"status":"ok","timestamp":1644995377479,"user_tz":-480,"elapsed":383,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"}}},"outputs":[],"source":["assert x.get_device() == 0"]},{"cell_type":"markdown","metadata":{"id":"r15Pg9FelpUL"},"source":["## GD vs. SGD"]},{"cell_type":"markdown","metadata":{"id":"QFVPl6r4ee4W"},"source":["### Gradient Descent\n","\n","In this section we are going to introduce the basic concepts underlying gradient descent. An understanding of gradient descent is key to understanding stochastic gradient descent algorithms. For instance, the optimization problem might diverge due to an overly large learning rate. This phenomenon can already be seen in gradient descent. Likewise, preconditioning is a common technique in gradient descent and carries over to more advanced algorithms. Let us start with a simple special case. Gradient descent in one dimension is an excellent example to explain why the gradient descent algorithm may reduce the value of the objective function."]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3585,"status":"ok","timestamp":1644995473155,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"ScPv0oseee4W","outputId":"4b4a5992-ea31-4673-a036-39a249c064aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: d2l in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n","Requirement already satisfied: matplotlib==3.3.3 in /usr/local/lib/python3.7/dist-packages (from d2l) (3.3.3)\n","Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from d2l) (2.25.1)\n","Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.18.5)\n","Requirement already satisfied: pandas==1.2.2 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.2.2)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.6.5)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (7.1.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l) (2018.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2021.10.8)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l) (1.15.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.1.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.5.2)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.0.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.9.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (0.18.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.10.0.2)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (5.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.11.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.7.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.1.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (21.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.0.1)\n"]}],"source":["!pip install d2l"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"lv8RomRUee4X","origin_pos":2,"tab":["pytorch"],"executionInfo":{"status":"ok","timestamp":1644995482110,"user_tz":-480,"elapsed":388,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"}}},"outputs":[],"source":["%matplotlib inline\n","from d2l import torch as d2l\n","import numpy as np\n","import torch"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"FC4tn9w5ee4X","origin_pos":4,"tab":["pytorch"],"executionInfo":{"status":"ok","timestamp":1644995483875,"user_tz":-480,"elapsed":2,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"}}},"outputs":[],"source":["f = lambda x: x**2  # Objective function\n","gradf = lambda x: 2 * x  # Its derivative"]},{"cell_type":"markdown","metadata":{"id":"BJLSwrfFee4X","origin_pos":5},"source":["Next, we use $x=10$ as the initial value and assume $\\eta=0.2$. Using gradient descent to iterate $x$ for 10 times we can see that, eventually, the value of $x$ approaches the optimal solution.\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1644995485852,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"3e1OFTaiee4X","origin_pos":6,"outputId":"a2295792-986b-410b-a714-49ecf0baa1a1","tab":["pytorch"]},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 10, x: 0.06046617599999997\n"]}],"source":["def gd(eta):\n","    x = 10.0\n","    results = [x]\n","    for i in range(10):\n","        x -= eta * gradf(x)\n","        results.append(float(x))\n","    print('epoch 10, x:', x)\n","    return results\n","\n","res = gd(0.2)"]},{"cell_type":"markdown","metadata":{"id":"76LE8cAfee4X","origin_pos":7},"source":["The progress of optimizing over $x$ can be plotted as follows.\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1644995517280,"user":{"displayName":"曾致崴","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10458202227634433365"},"user_tz":-480},"id":"IwxnGHVJee4X","origin_pos":8,"outputId":"f57c0419-672f-4c8d-ed04-2c2ae399a7fa","tab":["pytorch"]},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mdetermine\u001b[0m \u001b[0ma\u001b[0m \u001b[0msuitable\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0msaving\u001b[0m \u001b[0mto\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0meither\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0msupports\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mwhatever\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mget_registered_canvas_class\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m             \u001b[0mswitch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \"\"\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouse_grabber\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouse_grabber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0;34m\"\"\"Render the `.Figure`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mfollowing\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimplemented\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     functionality (though just implementing :meth:`draw_path` alone would\n\u001b[0m\u001b[1;32m    127\u001b[0m     give a highly capable backend):\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n","\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 252x180 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["def show_trace(res):\n","    n = max(abs(min(res)), abs(max(res)))\n","    f_line = torch.arange(-n, n, 0.01)\n","    d2l.set_figsize()\n","    d2l.plot([f_line, res], [[f(x) for x in f_line], [f(x) for x in res]], 'x', 'f(x)', fmts=['-', '-o'])\n","\n","show_trace(res)"]},{"cell_type":"markdown","metadata":{"id":"s_N41Vesee4X","origin_pos":9},"source":["#### Learning Rate\n","\n","The learning rate $\\eta$ can be set by the algorithm designer. If we use a learning rate that is too small, it will cause $x$ to update very slowly, requiring more iterations to get a better solution. To show what happens in such a case, consider the progress in the same optimization problem for $\\eta = 0.05$. As we can see, even after 10 steps we are still very far from the optimal solution.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YndYPToOee4Y","origin_pos":10,"tab":["pytorch"]},"outputs":[],"source":["show_trace(gd(0.05))"]},{"cell_type":"markdown","metadata":{"id":"wm6H9w3fee4Y","origin_pos":11},"source":["Conversely, if we use an excessively high learning rate, $\\left|\\eta f'(x)\\right|$ might be too large for the first-order Taylor expansion formula. That is, the term $\\mathcal{O}(\\eta^2 f'^2(x))$ in :eqref:`gd-taylor` might become significant. In this case, we cannot guarantee that the iteration of $x$ will be able to lower the value of $f(x)$. For example, when we set the learning rate to $\\eta=1.1$, $x$ overshoots the optimal solution $x=0$ and gradually diverges.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mC_Ns685ee4Y","origin_pos":12,"tab":["pytorch"]},"outputs":[],"source":["show_trace(gd(1.1))"]},{"cell_type":"markdown","metadata":{"id":"S2P18oUjee4Y","origin_pos":13},"source":["#### Local Minima\n","\n","To illustrate what happens for nonconvex functions consider the case of $f(x) = x \\cdot \\cos c x$. This function has infinitely many local minima. Depending on our choice of learning rate and depending on how well conditioned the problem is, we may end up with one of many solutions. The example below illustrates how an (unrealistically) high learning rate will lead to a poor local minimum.\n"]},{"cell_type":"markdown","metadata":{"id":"qPzSUUqye5ps","origin_pos":4},"source":["### Stochastic Gradient Updates\n","\n","In deep learning, the objective function is usually the average of the loss functions for each example in the training dataset. We assume that $f_i(\\mathbf{x})$ is the loss function of the training dataset with $n$ examples, an index of $i$, and parameter vector of $\\mathbf{x}$, then we have the objective function\n","\n","$$f(\\mathbf{x}) = \\frac{1}{n} \\sum_{i = 1}^n f_i(\\mathbf{x}).$$\n","\n","The gradient of the objective function at $\\mathbf{x}$ is computed as\n","\n","$$\\nabla f(\\mathbf{x}) = \\frac{1}{n} \\sum_{i = 1}^n \\nabla f_i(\\mathbf{x}).$$\n","\n","If gradient descent is used, the computing cost for each independent variable iteration is $\\mathcal{O}(n)$, which grows linearly with $n$. Therefore, when the model training dataset is large, the cost of gradient descent for each iteration will be very high.\n","\n","Stochastic gradient descent (SGD) reduces computational cost at each iteration. At each iteration of stochastic gradient descent, we uniformly sample an index $i\\in\\{1,\\ldots, n\\}$ for data examples at random, and compute the gradient $\\nabla f_i(\\mathbf{x})$ to update $\\mathbf{x}$:\n","\n","$$\\mathbf{x} \\leftarrow \\mathbf{x} - \\eta \\nabla f_i(\\mathbf{x}).$$\n","\n","Here, $\\eta$ is the learning rate. We can see that the computing cost for each iteration drops from $\\mathcal{O}(n)$ of the gradient descent to the constant $\\mathcal{O}(1)$. We should mention that the stochastic gradient $\\nabla f_i(\\mathbf{x})$ is the unbiased estimate of gradient $\\nabla f(\\mathbf{x})$.\n","\n","$$\\mathbb{E}_i \\nabla f_i(\\mathbf{x}) = \\frac{1}{n} \\sum_{i = 1}^n \\nabla f_i(\\mathbf{x}) = \\nabla f(\\mathbf{x}).$$\n","\n","This means that, on average, the stochastic gradient is a good estimate of the gradient.\n","\n","Now, we will compare it to gradient descent by adding random noise with a mean of 0 and a variance of 1 to the gradient to simulate a SGD.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSK2zdPae5pt","origin_pos":6,"tab":["pytorch"]},"outputs":[],"source":["f = lambda x1, x2: x1 ** 2 + 2 * x2 ** 2  # Objective\n","gradf = lambda x1, x2: (2 * x1, 4 * x2)  # Gradient\n","\n","def sgd(x1, x2, s1, s2):\n","    global lr  # Learning rate scheduler\n","    (g1, g2) = gradf(x1, x2)\n","    # Simulate noisy gradient\n","    g1 += torch.normal(0.0, 1, (1,))\n","    g2 += torch.normal(0.0, 1, (1,))\n","    eta_t = eta * lr()  # Learning rate at time t\n","    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)  # Update variables\n","\n","eta = 0.1\n","lr = (lambda: 1)  # Constant learning rate\n","d2l.show_trace_2d(f, d2l.train_2d(sgd, steps=50))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bh7pHNY0ee4Z","origin_pos":14,"tab":["pytorch"]},"outputs":[],"source":["c = torch.tensor(0.15 * np.pi)\n","f = lambda x: x * torch.cos(c * x)\n","gradf = lambda x: torch.cos(c * x) - c * x * torch.sin(c * x)\n","show_trace(gd(2))"]},{"cell_type":"markdown","metadata":{"id":"fwfIvA4lpiQt"},"source":["# Building Model: Linear Regression\n","\n","Now, we know how to do the basic computation using PyTorch. Let's start to build a simple linear regression model.\n","\n","First, we generate 100 x, y data points for training. The data points follow this formula: y = 3.0 * x + 1.0\n","\n","The goal is to regress W and b that fits the training data."]},{"cell_type":"markdown","metadata":{"id":"jOXHaB5-bbNR"},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCxWRpIlpocN"},"outputs":[],"source":["x_train = np.random.rand(100).astype(np.float32).reshape(-1,1)\n","y_correct = 3.0 * x_train + 1.0\n","\n","plt.plot(x_train, y_correct)"]},{"cell_type":"markdown","metadata":{"id":"T06iqj8DT_8p"},"source":["A model in PyTorch is a subclass of ```nn.Module```. There are several predefined layers and containers in the [ ```torch.nn```](https://pytorch.org/docs/stable/nn.html) module. We can use those to build more complex network structures.\n","\n","You can check out the layers we talked about in the lecture here:\n","\n","*   [```nn.Linear```](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear): fully connected layer\n","*   [```nn.Conv2d```](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d): convolution layer\n","* [```nn.MaxPool2d```](https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d): pooling\n","* [```nn.LSTM```](https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM): LSTM unit\n","\n","More complex neural networks are easily built using the predefined layers with the container classes ```Sequential``` and ```Concat```. \n","\n","The main method to implement in the ```nn.Module``` is ```forward```. It computes the output of the model given the input Tensor. The computation we put here defines the network architecture and how data flows between layers."]},{"cell_type":"markdown","metadata":{"id":"ePIqGAfebui5"},"source":["## Forward to compute prediction"]},{"cell_type":"markdown","metadata":{"id":"xk526Gw9UG0K"},"source":["A linear regression model is basically a single linear layer!\n","\n","We first define the layers we needed in ```__init__``` and then build the computation in ```forward```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"04SMw8E2UM29"},"outputs":[],"source":["class LinearRegressionModel(nn.Module):\n","\n","    def __init__(self, input_dim, output_dim):\n","\n","        super(LinearRegressionModel, self).__init__() \n","        self.linear = nn.Linear(input_dim, output_dim)\n","\n","    def forward(self, x):\n","        out = self.linear(x)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"BHt1-qv9UQWB"},"source":["We then instantiate the model for training. We will use the mean squared error ([`nn.MSELoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss)) as loss function and optimize the network with stochastic gradient descent ([`torch.optim.SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)).\n","\n","We need to specify the parameters we want to optimize in the first argument of the selected optimizer. Usually, that should be all parameters in the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtgkIIKLUUHk"},"outputs":[],"source":["model = LinearRegressionModel(1, 1)\n","\n","criterion = nn.MSELoss()"]},{"cell_type":"markdown","metadata":{"id":"nFvp-qzXedWz"},"source":["## Backprop"]},{"cell_type":"markdown","metadata":{"id":"KBxcz1PsgbkL"},"source":["### Train the Model\n","\n","Similar to what we did in the numpy example, at each training iteration, we perform one forward pass, get the loss, compute the gradients (using ```.backward()```), and update the parameters by taking a ```.step()``` with the optimizer.\n","\n","**Note** that we need to clear the gradients that are accumulated from previous training iterations first so we don't optimize against the old gradients stored in the variables. We can easily do it by calling ```optimizer.zero_grad()``` at the beginning of each iteration. "]},{"cell_type":"markdown","metadata":{"id":"x917xLvDSfzL"},"source":["\n","\n","[Tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard) is a utility to record and visualize the activations, weights, loss, etc of your network, during and after training. It greatly simplifies debugging and iterative development of the network architecture. It is highly recommended.\n","\n","To use TensorBoard in this notebook, we have to overcome two technical hurdles:\n"," 1. we will be using [PyTorch](https://pytorch.org/) to work with our networks, but as the name suggests, TensorBoard is designed to work with [TensorFlow](https://www.tensorflow.org/), a competing framework.\n"," 2. generally it is easiest to use TensorBoard when you're working on your local computer or on a computer on your local network, but in this tutorial we will run these notebooks on remote virtual machines via Colab.\n","\n","We will use an extension in Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fZTfj8uTT9F"},"outputs":[],"source":["from tensorflow import summary\n","\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"4fDSbmBRiK0G"},"source":["Let's do the training again and write summary to tensorboard. Let's get summary writers for traininng and testing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjjuDW-bjclM"},"outputs":[],"source":["import datetime\n","\n","current_time = str(datetime.datetime.now().timestamp())\n","train_log_dir = 'logs/tensorboard/train/' + current_time\n","test_log_dir = 'logs/tensorboard/test/' + current_time\n","train_summary_writer = summary.create_file_writer(train_log_dir)\n","#test_summary_writer = summary.create_file_writer(test_log_dir)"]},{"cell_type":"markdown","metadata":{"id":"IPlAiNQkVu9x"},"source":["### Part B: Please fill in the training code\n","\n","* zero_grad(): zero the gradients (this is needed because PyTorch accumulates gradients in all parameters every time we call loss.backward())\n","* forward: forward propagation of inputs: compute the activation of all units within the network\n","* compute the loss \n","* backpropagation: compute the numerical gradient of the loss with respect to all parameters, evaluated for the current values of the activations and the loss. As mentioned above, these values are stored locally within each parameter.\n","* step() to update weights: take a step with the optimizer we have defined above. The optimizer will go through all the parameters it know about (which we have specified when we created it), and update them according to the gradients it will find there, which we have computed when we performed backpropagation."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"c94pDxhgi00l","nbgrader":{"cell_type":"code","checksum":"f0d51f01b4a087fc741fc94a0c1089f9","grade":false,"grade_id":"cell-940cdcc11d64cf42","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["model = LinearRegressionModel(1, 1)\n","\n","criterion = nn.MSELoss()\n","learing_rate = 0.01\n","optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate)\n","\n","epochs = 2000\n","\n","for epoch in range(epochs):\n","    inputs = torch.from_numpy(x_train)\n","    labels = torch.from_numpy(y_correct)\n","\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    with train_summary_writer.as_default():\n","        summary.scalar('loss', loss.item(), epoch)\n","\n","    if epoch % 100 == 0:\n","        print('epoch {}, loss {}'.format(epoch, loss.item()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"executionInfo":{"elapsed":4047,"status":"ok","timestamp":1635085930613,"user":{"displayName":"Hsueh-Cheng Nick Wang,","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06179770656702341445"},"user_tz":-480},"id":"gy8T8FywVZrL","outputId":"87f6538c-a538-44fd-bb3a-632c7c56400c"},"outputs":[],"source":["%tensorboard --logdir logs/tensorboard"]},{"cell_type":"markdown","metadata":{"id":"aaTD3IxMlBcL"},"source":["### After the Training"]},{"cell_type":"markdown","metadata":{"id":"-gr_IINUlBcM"},"source":["After the model is trained, we can apply the ```forward``` method to get the prediction of any data point.\n","\n","We can also visualize it to see what the predictions look like!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCRg5bBtlBcM"},"outputs":[],"source":["predicted = model.forward(torch.from_numpy(x_train)).data.numpy()\n","\n","plt.plot(x_train, y_correct, 'go', label='from data', alpha=0.5)\n","plt.plot(x_train, predicted, label='prediction', alpha=0.5)\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"dRapkppmlBcM"},"source":["In case anything goes wrong and you want to check the learned parameters of your model, you can inspect the `weight` and `bias` of a layer as follows. "]},{"cell_type":"markdown","metadata":{"id":"suXeDjUpVhQh"},"source":["### Part B: inspect the weight and bias (1 point)"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"LHdrCzORlBcM","nbgrader":{"cell_type":"code","checksum":"9a996065790213e72f0763bb74a70bf3","grade":true,"grade_id":"cell-6922ea630ae9fa1d","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["print(model.linear.weight)\n","print(model.linear.bias)\n","\n","assert abs(model.linear.weight.detach().numpy() -3) < 0.2 \n","assert abs(model.linear.bias.detach().numpy() -1) < 0.2 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z--20Spnm2YC"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["s_N41Vesee4X"],"name":"ai_intro_2021_05_01_pytorch_intro.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}